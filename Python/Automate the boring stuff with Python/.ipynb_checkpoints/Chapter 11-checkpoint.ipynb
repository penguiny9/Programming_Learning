{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11 从Web抓取信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 项目：利用webbrowser模块的mapIt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "webbrowser.open('http://inventwithpython.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.1 弄清楚URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.2 处理命令行参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser, sys\n",
    "if len(sys.argv)>1:\n",
    "    #Get address from command line.\n",
    "    address=' '.join(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.3 处理剪贴板内容，加载浏览器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser, sys\n",
    "if len(sys.argv)>1:\n",
    "    #Get address from command line.\n",
    "    address=' '.join(sys.argv[1:])\n",
    "else:\n",
    "    #Get address from clipboard.\n",
    "    address=pyperClip.paste()\n",
    "webbrowser.open('https://ditu.amap.com/search?query='+address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1.4类似程序的想法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 用requests模块从Web下载文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.1 用requests.get()函数下载一个网页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "res=requests.get('http://www.gutenberg.org/cache/epub/1112/pg1112.txt')\n",
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.status_code==requests.codes.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179378"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of Romeo and Juliet, by William Shakespeare\r\n",
      "\r\n",
      "\r\n",
      "*******************************************************************\r\n",
      "THIS EBOOK WAS ONE OF PROJECT GUTENBERG'S EARLY FILES PRODUCED AT A\r\n",
      "TIME WHEN PROOFING METHODS AND TOO\n"
     ]
    }
   ],
   "source": [
    "print(res.text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.2 检查错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Response.raise_for_status of <Response [404]>>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=requests.get('http://inventwithpython.com/page_that_does_not_exist')\n",
    "res.raise_for_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a problem: 404 Client Error: Not Found for url: http://inventwithpython.com/page_that_does_not_exist\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "res=requests.get('http://inventwithpython.com/page_that_does_not_exist')\n",
    "try:\n",
    "    res.raise_for_status()\n",
    "except Exception as exc:\n",
    "    print('There was a problem: %s' %(exc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 将下载的文件保存到硬盘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "res=requests.get('http://www.gutenberg.org/cache/epub/1112/pg1112.txt')\n",
    "res.raise_for_status()\n",
    "playFile=open('RomeoAndJuliet.txt','wb')\n",
    "for chunk in res.iter_content(100000):\n",
    "    playFile.write(chunk)\n",
    "playFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.1 学习HTML的资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.2 快速复习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.3 查看网页的HTML源代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.4 代开浏览器的开发者工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.5 使用开发者工具来寻找HTML元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 用BeaurtifulSoup模块解析HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.1 从HTML创建一个BeautifulSoup对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, bs4\n",
    "res=requests.get('https://forecast.weather.gov/')\n",
    "res.raise_for_status()\n",
    "noStarchSoup=bs4.BeautifulSoup(res.text)\n",
    "type(noStarchSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleFile=open('example.html')\n",
    "exampleSoup=bs4.BeautifulSoup(exampleFile)\n",
    "type(exampleSoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.2 用select()方法寻找元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "exampleFile=open('example.html')\n",
    "exampleSoup=bs4.BeautifulSoup(exampleFile.read())\n",
    "elems=exampleSoup.select('#author')\n",
    "type(elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(elems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Al Sweigart'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elems[0].getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<span id=\"author\">Al Sweigart</span>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(elems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'author'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elems[0].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>Download my <strong>Python</strong> book from <a href=\"http://inventwithpython.com\">my website</a>.</p>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pElems=exampleSoup.select('p')\n",
    "str(pElems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Download my Python book from my website.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pElems[0].getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p class=\"slogan\">Learn Python the easy way!</p>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(pElems[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learn Python the easy way!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pElems[1].getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>By <span id=\"author\">Al Sweigart</span></p>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(pElems[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'By Al Sweigart'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pElems[2].getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.3 通过元素的属性获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<span id=\"author\">Al Sweigart</span>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "soup=bs4.BeautifulSoup(open('example.html'))\n",
    "spanElem=soup.select('span')[0]\n",
    "str(spanElem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'author'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanElem.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanElem.get('some_noneexistent_addr')==None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'author'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanElem.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6 项目：'I'm Feeling Lucky' Google查找"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.6.1 获取命令行参数，并请求查找页面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baiduing...\n"
     ]
    }
   ],
   "source": [
    "import requests, sys, webbrowser, bs4\n",
    "\n",
    "print('Baiduing...')\n",
    "res=requests.get('http://baidu.com/s?wd='+' '.join(sys.argv[1:]))\n",
    "res.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  11.6.2 找到所有的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, sys, webbrowser, bs4\n",
    "\n",
    "print('Baiduing...')\n",
    "res=requests.get('http://baidu.com/s?wd='+' '.join(sys.argv[1:]))\n",
    "res.raise_for_status()\n",
    "\n",
    "#Retrieve top search result links.\n",
    "soup=bs4.BeautifulSoup(res.text)\n",
    "\n",
    "#Open a browser tab for each result.\n",
    "linkElems=soup.select('.r a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.6.2 针对每个结果打开Web浏览器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, sys, webbrowser, bs4\n",
    "\n",
    "print('Baiduing...')\n",
    "res=requests.get('http://baidu.com/s?wd='+' '.join(sys.argv[1:]))\n",
    "res.raise_for_status()\n",
    "\n",
    "#Retrieve top search result links.\n",
    "soup=bs4.BeautifulSoup(res.text)\n",
    "\n",
    "#Open a browser tab for each result.\n",
    "linkElems=soup.select('.r a')\n",
    "\n",
    "#Open a browser tab for each result\n",
    "linkElems=soup.select('.r a')\n",
    "numOpen=min(5, len(linkElems))\n",
    "for i in range(numOpen):\n",
    "    webbrowser.open('http://baidu.com/s?wd='+linkElems[i].get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.6.4 类似程序的想法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.7 项目：下载所有XKCD漫画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.7.1 设计程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, bs4\n",
    "\n",
    "url='http://xkcd.com'\n",
    "os.makedirs('xkcd', exist_ok=True)\n",
    "while not url.endswith('#'):\n",
    "    #TODO: Download the page\n",
    "    \n",
    "    #TODO: Find the URL of the comic image.\n",
    "    \n",
    "    #TODO: Download the image.\n",
    "    \n",
    "    #TODO: Save the image to ./xkcd.\n",
    "    \n",
    "    #TODO: Get the Prev button's url\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.7.2 下载网页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, bs4\n",
    "\n",
    "url='http://xkcd.com'\n",
    "os.makedirs('xkcd', exist_ok=True)\n",
    "\n",
    "while not url.endswith('#'):\n",
    "    \n",
    "    #Download the page\n",
    "    print('Downloading page %s...' %url)\n",
    "    res=requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup=bs4.BeautifulSoup(res.text)\n",
    "    \n",
    "    #TODO: Find the URL of the comic image.\n",
    "    \n",
    "    #TODO: Download the image.\n",
    "    \n",
    "    #TODO: Save the image to ./xkcd.\n",
    "    \n",
    "    #TODO: Get the Prev button's url\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.7.3 寻找和下载漫画图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, bs4\n",
    "\n",
    "url='http://xkcd.com'\n",
    "os.makedirs('xkcd', exist_ok=True)\n",
    "\n",
    "while not url.endswith('#'):\n",
    "    \n",
    "    #Download the page\n",
    "    print('Downloading page %s...' %url)\n",
    "    res=requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup=bs4.BeautifulSoup(res.text)\n",
    "    \n",
    "    #TODO: Find the URL of the comic image.\n",
    "    comicElem=soup.select('#comic img')\n",
    "    if comicElem==[]:\n",
    "        print('Could not find comic image.')\n",
    "    else:\n",
    "        comicUrl='http:'+comicElem[0].get('src')\n",
    "        \n",
    "        #Download the image.\n",
    "        print('Downloading image %s...'%(comicUrl))\n",
    "    \n",
    "    #TODO: Save the image to ./xkcd.\n",
    "    \n",
    "    #TODO: Get the Prev button's url\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.7.4 保存图像，找到前一张漫画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading page http://xkcd.com...\n",
      "Downloading image http://imgs.xkcd.com/comics/spreadsheets.png...\n",
      "Downloading page http://xkcd.com/2179/...\n",
      "Downloading image http://imgs.xkcd.com/comics/nws_warnings.png...\n",
      "Downloading page http://xkcd.com/2178/...\n",
      "Downloading image http://imgs.xkcd.com/comics/expiration_date_high_score.png...\n",
      "Downloading page http://xkcd.com/2177/...\n",
      "Downloading image http://imgs.xkcd.com/comics/gastroenterology.png...\n",
      "Downloading page http://xkcd.com/2176/...\n",
      "Downloading image http://imgs.xkcd.com/comics/how_hacking_works.png...\n",
      "Downloading page http://xkcd.com/2175/...\n",
      "Downloading image http://imgs.xkcd.com/comics/flag_interpretation.png...\n",
      "Downloading page http://xkcd.com/2174/...\n",
      "Downloading image http://imgs.xkcd.com/comics/first_news_memory.png...\n",
      "Downloading page http://xkcd.com/2173/...\n",
      "Downloading image http://imgs.xkcd.com/comics/trained_a_neural_net.png...\n",
      "Downloading page http://xkcd.com/2172/...\n",
      "Downloading image http://imgs.xkcd.com/comics/lunar_cycles.png...\n",
      "Downloading page http://xkcd.com/2171/...\n",
      "Downloading image http://imgs.xkcd.com/comics/shadow_biosphere.png...\n",
      "Downloading page http://xkcd.com/2170/...\n",
      "Downloading image http://imgs.xkcd.com/comics/coordinate_precision.png...\n",
      "Downloading page http://xkcd.com/2169/...\n",
      "Downloading image http://imgs.xkcd.com/comics/predictive_models.png...\n",
      "Downloading page http://xkcd.com/2168/...\n",
      "Downloading image http://imgs.xkcd.com/comics/reading_in_the_original.png...\n",
      "Downloading page http://xkcd.com/2167/...\n",
      "Downloading image http://imgs.xkcd.com/comics/motivated_reasoning_olympics.png...\n",
      "Downloading page http://xkcd.com/2166/...\n",
      "Downloading image http://imgs.xkcd.com/comics/stack.png...\n",
      "Downloading page http://xkcd.com/2165/...\n",
      "Downloading image http://imgs.xkcd.com/comics/millennials.png...\n",
      "Downloading page http://xkcd.com/2164/...\n",
      "Downloading image http://imgs.xkcd.com/comics/glacier.png...\n",
      "Downloading page http://xkcd.com/2163/...\n",
      "Downloading image http://imgs.xkcd.com/comics/chernobyl.png...\n",
      "Downloading page http://xkcd.com/2162/...\n",
      "Downloading image http://imgs.xkcd.com/comics/literary_opinions.png...\n",
      "Downloading page http://xkcd.com/2161/...\n",
      "Downloading image http://imgs.xkcd.com/comics/an_apple_a_day.png...\n",
      "Downloading page http://xkcd.com/2160/...\n",
      "Downloading image http://imgs.xkcd.com/comics/ken_burns_theory.png...\n",
      "Downloading page http://xkcd.com/2159/...\n",
      "Downloading image http://imgs.xkcd.com/comics/comments.png...\n",
      "Downloading page http://xkcd.com/2158/...\n",
      "Downloading image http://imgs.xkcd.com/comics/qualifiers.png...\n",
      "Downloading page http://xkcd.com/2157/...\n",
      "Downloading image http://imgs.xkcd.com/comics/diploma_legal_notes.png...\n",
      "Downloading page http://xkcd.com/2156/...\n",
      "Downloading image http://imgs.xkcd.com/comics/ufo.png...\n",
      "Downloading page http://xkcd.com/2155/...\n",
      "Downloading image http://imgs.xkcd.com/comics/swimming.png...\n",
      "Downloading page http://xkcd.com/2154/...\n",
      "Downloading image http://imgs.xkcd.com/comics/motivation.png...\n",
      "Downloading page http://xkcd.com/2153/...\n",
      "Downloading image http://imgs.xkcd.com/comics/effects_of_high_altitude.png...\n",
      "Downloading page http://xkcd.com/2152/...\n",
      "Downloading image http://imgs.xkcd.com/comics/westerns.png...\n",
      "Downloading page http://xkcd.com/2151/...\n",
      "Downloading image http://imgs.xkcd.com/comics/a_b.png...\n",
      "Downloading page http://xkcd.com/2150/...\n",
      "Downloading image http://imgs.xkcd.com/comics/xkeyboarcd.png...\n",
      "Downloading page http://xkcd.com/2149/...\n",
      "Downloading image http://imgs.xkcd.com/comics/alternate_histories.png...\n",
      "Downloading page http://xkcd.com/2148/...\n",
      "Downloading image http://imgs.xkcd.com/comics/cubesat_launch.png...\n",
      "Downloading page http://xkcd.com/2147/...\n",
      "Downloading image http://imgs.xkcd.com/comics/appendicitis.png...\n",
      "Downloading page http://xkcd.com/2146/...\n",
      "Downloading image http://imgs.xkcd.com/comics/waiting_for_the_but.png...\n",
      "Downloading page http://xkcd.com/2145/...\n",
      "Downloading image http://imgs.xkcd.com/comics/heists_and_escapes.png...\n",
      "Downloading page http://xkcd.com/2144/...\n",
      "Downloading image http://imgs.xkcd.com/comics/adjusting_a_chair.png...\n",
      "Downloading page http://xkcd.com/2143/...\n",
      "Downloading image http://imgs.xkcd.com/comics/disk_usage.png...\n",
      "Downloading page http://xkcd.com/2142/...\n",
      "Downloading image http://imgs.xkcd.com/comics/dangerous_fields.png...\n",
      "Downloading page http://xkcd.com/2141/...\n",
      "Downloading image http://imgs.xkcd.com/comics/ui_vs_ux.png...\n",
      "Downloading page http://xkcd.com/2140/...\n",
      "Downloading image http://imgs.xkcd.com/comics/reinvent_the_wheel.png...\n",
      "Downloading page http://xkcd.com/2139/...\n",
      "Downloading image http://imgs.xkcd.com/comics/email_settings.png...\n",
      "Downloading page http://xkcd.com/2138/...\n",
      "Downloading image http://imgs.xkcd.com/comics/wanna_see_the_code.png...\n",
      "Downloading page http://xkcd.com/2137/...\n",
      "Downloading image http://imgs.xkcd.com/comics/text_entry.png...\n",
      "Downloading page http://xkcd.com/2136/...\n",
      "Downloading image http://imgs.xkcd.com/comics/election_commentary.png...\n",
      "Downloading page http://xkcd.com/2135/...\n",
      "Downloading image http://imgs.xkcd.com/comics/m87_black_hole_size_comparison.png...\n",
      "Downloading page http://xkcd.com/2134/...\n",
      "Downloading image http://imgs.xkcd.com/comics/too_much_talking.png...\n",
      "Downloading page http://xkcd.com/2133/...\n",
      "Downloading image http://imgs.xkcd.com/comics/eht_black_hole_picture.png...\n",
      "Downloading page http://xkcd.com/2132/...\n",
      "Downloading image http://imgs.xkcd.com/comics/percentage_styles.png...\n",
      "Downloading page http://xkcd.com/2131/...\n",
      "Downloading image http://imgs.xkcd.com/comics/emojidome.png...\n",
      "Downloading page http://xkcd.com/2130/...\n",
      "Downloading image http://imgs.xkcd.com/comics/industry_nicknames.png...\n",
      "Downloading page http://xkcd.com/2129/...\n",
      "Downloading image http://imgs.xkcd.com/comics/1921_fact_checker.png...\n",
      "Downloading page http://xkcd.com/2128/...\n",
      "Downloading image http://imgs.xkcd.com/comics/new_robot.png...\n",
      "Downloading page http://xkcd.com/2127/...\n",
      "Downloading image http://imgs.xkcd.com/comics/panama_canal.png...\n",
      "Downloading page http://xkcd.com/2126/...\n",
      "Downloading image http://imgs.xkcd.com/comics/google_trends_maps.png...\n",
      "Downloading page http://xkcd.com/2125/...\n",
      "Downloading image http://imgs.xkcd.com/comics/luna_2.png...\n",
      "Downloading page http://xkcd.com/2124/...\n",
      "Downloading image http://imgs.xkcd.com/comics/space_mission_hearing.png...\n",
      "Downloading page http://xkcd.com/2123/...\n",
      "Downloading image http://imgs.xkcd.com/comics/meta_collecting.png...\n",
      "Downloading page http://xkcd.com/2122/...\n",
      "Downloading image http://imgs.xkcd.com/comics/size_venn_diagram.png...\n",
      "Downloading page http://xkcd.com/2121/...\n",
      "Downloading image http://imgs.xkcd.com/comics/light_pollution.png...\n",
      "Downloading page http://xkcd.com/2120/...\n",
      "Downloading image http://imgs.xkcd.com/comics/brain_hemispheres.png...\n",
      "Downloading page http://xkcd.com/2119/...\n",
      "Downloading image http://imgs.xkcd.com/comics/video_orientation.png...\n",
      "Downloading page http://xkcd.com/2118/...\n",
      "Downloading image http://imgs.xkcd.com/comics/normal_distribution.png...\n",
      "Downloading page http://xkcd.com/2117/...\n",
      "Downloading image http://imgs.xkcd.com/comics/differentiation_and_integration.png...\n",
      "Downloading page http://xkcd.com/2116/...\n",
      "Downloading image http://imgs.xkcd.com/comics/norm_normal_file_format.png...\n",
      "Downloading page http://xkcd.com/2115/...\n",
      "Downloading image http://imgs.xkcd.com/comics/plutonium.png...\n",
      "Downloading page http://xkcd.com/2114/...\n",
      "Downloading image http://imgs.xkcd.com/comics/launch_conditions.png...\n",
      "Downloading page http://xkcd.com/2113/...\n",
      "Downloading image http://imgs.xkcd.com/comics/physics_suppression.png...\n",
      "Downloading page http://xkcd.com/2112/...\n",
      "Downloading image http://imgs.xkcd.com/comics/night_shift.png...\n",
      "Downloading page http://xkcd.com/2111/...\n",
      "Downloading image http://imgs.xkcd.com/comics/opportunity_rover.png...\n",
      "Downloading page http://xkcd.com/2110/...\n",
      "Downloading image http://imgs.xkcd.com/comics/error_bars.png...\n",
      "Downloading page http://xkcd.com/2109/...\n",
      "Downloading image http://imgs.xkcd.com/comics/invisible_formatting.png...\n",
      "Downloading page http://xkcd.com/2108/...\n",
      "Downloading image http://imgs.xkcd.com/comics/carbonated_beverage_language_map.png...\n",
      "Downloading page http://xkcd.com/2107/...\n",
      "Downloading image http://imgs.xkcd.com/comics/launch_risk.png...\n",
      "Downloading page http://xkcd.com/2106/...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image http://imgs.xkcd.com/comics/sharing_options.png...\n",
      "Downloading page http://xkcd.com/2105/...\n",
      "Downloading image http://imgs.xkcd.com/comics/modern_osi_model.png...\n",
      "Downloading page http://xkcd.com/2104/...\n",
      "Downloading image http://imgs.xkcd.com/comics/biff_tannen.png...\n",
      "Downloading page http://xkcd.com/2103/...\n",
      "Downloading image http://imgs.xkcd.com/comics/midcontinent_rift_system.png...\n",
      "Downloading page http://xkcd.com/2102/...\n",
      "Downloading image http://imgs.xkcd.com/comics/internet_archive.png...\n",
      "Downloading page http://xkcd.com/2101/...\n",
      "Downloading image http://imgs.xkcd.com/comics/technical_analysis.png...\n",
      "Downloading page http://xkcd.com/2100/...\n",
      "Downloading image http://imgs.xkcd.com/comics/models_of_the_atom.png...\n",
      "Downloading page http://xkcd.com/2099/...\n",
      "Downloading image http://imgs.xkcd.com/comics/missal_of_silos.png...\n",
      "Downloading page http://xkcd.com/2098/...\n",
      "Downloading image http://imgs.xkcd.com/comics/magnetic_pole.png...\n",
      "Downloading page http://xkcd.com/2097/...\n",
      "Downloading image http://imgs.xkcd.com/comics/thor_tools.png...\n",
      "Downloading page http://xkcd.com/2096/...\n",
      "Downloading image http://imgs.xkcd.com/comics/mattresses.png...\n",
      "Downloading page http://xkcd.com/2095/...\n",
      "Downloading image http://imgs.xkcd.com/comics/marsiforming.png...\n",
      "Downloading page http://xkcd.com/2094/...\n",
      "Downloading image http://imgs.xkcd.com/comics/short_selling.png...\n",
      "Downloading page http://xkcd.com/2093/...\n",
      "Downloading image http://imgs.xkcd.com/comics/reminders.png...\n",
      "Downloading page http://xkcd.com/2092/...\n",
      "Downloading image http://imgs.xkcd.com/comics/consensus_new_year.png...\n",
      "Downloading page http://xkcd.com/2091/...\n",
      "Downloading image http://imgs.xkcd.com/comics/million_billion_trillion.png...\n",
      "Downloading page http://xkcd.com/2090/...\n",
      "Downloading image http://imgs.xkcd.com/comics/feathered_dinosaur_venn_diagram.png...\n",
      "Downloading page http://xkcd.com/2089/...\n",
      "Downloading image http://imgs.xkcd.com/comics/christmas_eve_eve.png...\n",
      "Downloading page http://xkcd.com/2088/...\n",
      "Downloading image http://imgs.xkcd.com/comics/schwarzschilds_cat.png...\n",
      "Downloading page http://xkcd.com/2087/...\n",
      "Downloading image http://imgs.xkcd.com/comics/rocket_launch.png...\n",
      "Downloading page http://xkcd.com/2086/...\n",
      "Downloading image http://imgs.xkcd.com/comics/history_department.png...\n",
      "Downloading page http://xkcd.com/2085/...\n",
      "Downloading image http://imgs.xkcd.com/comics/arxiv.png...\n",
      "Downloading page http://xkcd.com/2084/...\n",
      "Downloading image http://imgs.xkcd.com/comics/fdr.png...\n",
      "Downloading page http://xkcd.com/2083/...\n",
      "Downloading image http://imgs.xkcd.com/comics/laptop_issues.png...\n",
      "Downloading page http://xkcd.com/2082/...\n",
      "Downloading image http://imgs.xkcd.com/comics/mercator_projection.png...\n",
      "Downloading page http://xkcd.com/2081/...\n",
      "Downloading image http://imgs.xkcd.com/comics/middle_latitudes.png...\n",
      "Downloading page http://xkcd.com/2080/...\n",
      "Downloading image http://imgs.xkcd.com/comics/cohort_and_age_effects.png...\n",
      "Downloading page http://xkcd.com/2079/...\n",
      "Downloading image http://imgs.xkcd.com/comics/alpha_centauri.png...\n",
      "Downloading page http://xkcd.com/2078/...\n",
      "Downloading image http://imgs.xkcd.com/comics/popper.png...\n",
      "Downloading page http://xkcd.com/2077/...\n",
      "Downloading image http://imgs.xkcd.com/comics/heist.png...\n",
      "Downloading page http://xkcd.com/2076/...\n",
      "Downloading image http://imgs.xkcd.com/comics/horror_movies_2.png...\n",
      "Downloading page http://xkcd.com/2075/...\n",
      "Downloading image http://imgs.xkcd.com/comics/update_your_address.png...\n",
      "Downloading page http://xkcd.com/2074/...\n",
      "Downloading image http://imgs.xkcd.com/comics/airplanes_and_spaceships.png...\n",
      "Downloading page http://xkcd.com/2073/...\n",
      "Downloading image http://imgs.xkcd.com/comics/kilogram.png...\n",
      "Downloading page http://xkcd.com/2072/...\n",
      "Downloading image http://imgs.xkcd.com/comics/evaluating_tech_things.png...\n",
      "Downloading page http://xkcd.com/2071/...\n",
      "Downloading image http://imgs.xkcd.com/comics/indirect_detection.png...\n",
      "Downloading page http://xkcd.com/2070/...\n",
      "Downloading image http://imgs.xkcd.com/comics/trig_identities.png...\n",
      "Downloading page http://xkcd.com/2069/...\n",
      "Downloading image http://imgs.xkcd.com/comics/wishlist.png...\n",
      "Downloading page http://xkcd.com/2068/...\n",
      "Downloading image http://imgs.xkcd.com/comics/election_night.png...\n",
      "Downloading page http://xkcd.com/2067/...\n",
      "Downloading image http:/2067/asset/challengers_header.png...\n",
      "Downloading page http://xkcd.com/2066/...\n",
      "Downloading image http://imgs.xkcd.com/comics/ballot_selfies.png...\n",
      "Downloading page http://xkcd.com/2065/...\n",
      "Downloading image http://imgs.xkcd.com/comics/who_sends_the_first_text.png...\n",
      "Downloading page http://xkcd.com/2064/...\n",
      "Downloading image http://imgs.xkcd.com/comics/im_a_car.png...\n",
      "Downloading page http://xkcd.com/2063/...\n",
      "Downloading image http://imgs.xkcd.com/comics/carnot_cycle.png...\n",
      "Downloading page http://xkcd.com/2062/...\n",
      "Downloading image http://imgs.xkcd.com/comics/barnards_star.png...\n",
      "Downloading page http://xkcd.com/2061/...\n",
      "Downloading image http://imgs.xkcd.com/comics/tectonics_game.png...\n",
      "Downloading page http://xkcd.com/2060/...\n",
      "Downloading image http://imgs.xkcd.com/comics/hygrometer.png...\n",
      "Downloading page http://xkcd.com/2059/...\n",
      "Downloading image http://imgs.xkcd.com/comics/modified_bayes_theorem.png...\n",
      "Downloading page http://xkcd.com/2058/...\n",
      "Downloading image http://imgs.xkcd.com/comics/rock_wall.png...\n",
      "Downloading page http://xkcd.com/2057/...\n",
      "Downloading image http://imgs.xkcd.com/comics/internal_monologues.png...\n",
      "Downloading page http://xkcd.com/2056/...\n",
      "Downloading image http://imgs.xkcd.com/comics/horror_movies.png...\n",
      "Downloading page http://xkcd.com/2055/...\n",
      "Downloading image http://imgs.xkcd.com/comics/bluetooth.png...\n",
      "Downloading page http://xkcd.com/2054/...\n",
      "Downloading image http://imgs.xkcd.com/comics/data_pipeline.png...\n",
      "Downloading page http://xkcd.com/2053/...\n",
      "Downloading image http://imgs.xkcd.com/comics/incoming_calls.png...\n",
      "Downloading page http://xkcd.com/2052/...\n",
      "Downloading image http://imgs.xkcd.com/comics/stanislav_petrov_day.png...\n",
      "Downloading page http://xkcd.com/2051/...\n",
      "Downloading image http://imgs.xkcd.com/comics/bad_opinions.png...\n",
      "Downloading page http://xkcd.com/2050/...\n",
      "Downloading image http://imgs.xkcd.com/comics/6_6_time.png...\n",
      "Downloading page http://xkcd.com/2049/...\n",
      "Downloading image http://imgs.xkcd.com/comics/unfulfilling_toys.png...\n",
      "Downloading page http://xkcd.com/2048/...\n",
      "Downloading image http://imgs.xkcd.com/comics/curve_fitting.png...\n",
      "Downloading page http://xkcd.com/2047/...\n",
      "Downloading image http://imgs.xkcd.com/comics/beverages.png...\n",
      "Downloading page http://xkcd.com/2046/...\n",
      "Downloading image http://imgs.xkcd.com/comics/trum.png...\n",
      "Downloading page http://xkcd.com/2045/...\n",
      "Downloading image http://imgs.xkcd.com/comics/social_media_announcement.png...\n",
      "Downloading page http://xkcd.com/2044/...\n",
      "Downloading image http://imgs.xkcd.com/comics/sandboxing_cycle.png...\n",
      "Downloading page http://xkcd.com/2043/...\n",
      "Downloading image http://imgs.xkcd.com/comics/boathouses_and_houseboats.png...\n",
      "Downloading page http://xkcd.com/2042/...\n",
      "Downloading image http://imgs.xkcd.com/comics/rolles_theorem.png...\n",
      "Downloading page http://xkcd.com/2041/...\n",
      "Downloading image http://imgs.xkcd.com/comics/frontiers.png...\n",
      "Downloading page http://xkcd.com/2040/...\n",
      "Downloading image http://imgs.xkcd.com/comics/sibling_in_law.png...\n",
      "Downloading page http://xkcd.com/2039/...\n",
      "Downloading image http://imgs.xkcd.com/comics/begging_the_question.png...\n",
      "Downloading page http://xkcd.com/2038/...\n",
      "Downloading image http://imgs.xkcd.com/comics/hazard_symbol.png...\n",
      "Downloading page http://xkcd.com/2037/...\n",
      "Downloading image http://imgs.xkcd.com/comics/supreme_court_bracket.png...\n",
      "Downloading page http://xkcd.com/2036/...\n",
      "Downloading image http://imgs.xkcd.com/comics/edgelord.png...\n",
      "Downloading page http://xkcd.com/2035/...\n",
      "Downloading image http://imgs.xkcd.com/comics/dark_matter_candidates.png...\n",
      "Downloading page http://xkcd.com/2034/...\n",
      "Downloading image http://imgs.xkcd.com/comics/equations.png...\n",
      "Downloading page http://xkcd.com/2033/...\n",
      "Downloading image http://imgs.xkcd.com/comics/repair_or_replace.png...\n",
      "Downloading page http://xkcd.com/2032/...\n",
      "Downloading image http://imgs.xkcd.com/comics/word_puzzles.png...\n",
      "Downloading page http://xkcd.com/2031/...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image http://imgs.xkcd.com/comics/pie_charts.png...\n",
      "Downloading page http://xkcd.com/2030/...\n",
      "Downloading image http://imgs.xkcd.com/comics/voting_software.png...\n",
      "Downloading page http://xkcd.com/2029/...\n",
      "Downloading image http://imgs.xkcd.com/comics/disaster_movie.png...\n",
      "Downloading page http://xkcd.com/2028/...\n",
      "Downloading image http://imgs.xkcd.com/comics/complex_numbers.png...\n",
      "Downloading page http://xkcd.com/2027/...\n",
      "Downloading image http://imgs.xkcd.com/comics/lightning_distance.png...\n",
      "Downloading page http://xkcd.com/2026/...\n",
      "Downloading image http://imgs.xkcd.com/comics/heat_index.png...\n",
      "Downloading page http://xkcd.com/2025/...\n",
      "Downloading image http://imgs.xkcd.com/comics/peer_review.png...\n",
      "Downloading page http://xkcd.com/2024/...\n",
      "Downloading image http://imgs.xkcd.com/comics/light_hacks.png...\n",
      "Downloading page http://xkcd.com/2023/...\n",
      "Downloading image http://imgs.xkcd.com/comics/y_axis.png...\n",
      "Downloading page http://xkcd.com/2022/...\n",
      "Downloading image http://imgs.xkcd.com/comics/sports_champions.png...\n",
      "Downloading page http://xkcd.com/2021/...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-2ffa24584087>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#Download the page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloading page %s...'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0msoup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests, os, bs4\n",
    "\n",
    "url='http://xkcd.com'\n",
    "os.makedirs('xkcd', exist_ok=True)\n",
    "\n",
    "while not url.endswith('#'):\n",
    "    \n",
    "    #Download the page\n",
    "    print('Downloading page %s...' %url)\n",
    "    res=requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup=bs4.BeautifulSoup(res.text)\n",
    "    \n",
    "    #Find the URL of the comic image.\n",
    "    comicElem=soup.select('#comic img')\n",
    "    if comicElem==[]:\n",
    "        print('Could not find comic image.')\n",
    "    else:\n",
    "        comicUrl='http:'+comicElem[0].get('src')\n",
    "        \n",
    "        #Download the image.\n",
    "        print('Downloading image %s...'%(comicUrl))\n",
    "    \n",
    "    #Save the image to ./xkcd.\n",
    "    imageFile=open(os.path.join('xkcd',os.path.basename(comicUrl)),'wb')\n",
    "    for chunk in res.iter_content(100000):\n",
    "        imageFile.write(chunk)\n",
    "    imageFile.close()\n",
    "    \n",
    "    #Get the Prev button's url\n",
    "    prevLink=soup.select('a[rel=\"prev\"]')[0]\n",
    "    url='http://xkcd.com'+prevLink.get('href')\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.8 用selenium模块控制浏览器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.8.1 启动selenium控制的浏览器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "browser=webdriver.Firefox()\n",
    "type(browser)\n",
    "browser.get('http://inventwithpython.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.8.2 在页面中寻找元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found <blockquote> element with that class name!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "browser=webdriver.Firefox()\n",
    "type(browser)\n",
    "browser.get('http://inventwithpython.com')\n",
    "try:\n",
    "    elem=browser.find_element_by_class_name('testimonial')\n",
    "    print('Found <%s> element with that class name!' %(elem.tag_name))\n",
    "except:\n",
    "    print('Was not able to find an element with that name.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.8.3 点击页面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selenium.webdriver.firefox.webelement.FirefoxWebElement"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "browser=webdriver.Firefox()\n",
    "browser.get('http://inventwithpython.com')\n",
    "linkElem=browser.find_element_by_link_text('Read Online for Free')\n",
    "type(linkElem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkElem.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.8.4 填写并提交表单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "browser=webdriver.Firefox()\n",
    "browser.get('https://mail.163.com')\n",
    "linkElem=browser.find_element_by_link_text('密码登录')\n",
    "linkElem.click()\n",
    "\n",
    "time.sleep(5)\n",
    "browser.switch_to.frame(browser.find_element_by_tag_name('iframe'))\n",
    "emailElem=browser.find_element_by_name(\"email\")\n",
    "emailElem.send_keys('peitan1989')\n",
    "passwordElem=browser.find_element_by_name(\"password\")\n",
    "passwordElem.send_keys('112358Penny')\n",
    "browser.find_element_by_id('dologin').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.8.5 发送特殊键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "browser=webdriver.Firefox()\n",
    "browser.get('http://nostarch.com')\n",
    "htmlElem=browser.find_element_by_tag_name('html')\n",
    "htmlElem.send_keys(Keys.END)   #scrolls to bottom\n",
    "htmlElem.send_keys(Keys.HOME)  #scroll_to_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.8.6 点击浏览器按钮"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "browser.back()点击“返回”按钮\n",
    "browser.forward()点击“前进”按钮\n",
    "browser.refresh()点击“刷新”按钮\n",
    "browser.quit()点击“关闭”按钮"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
